# -*- coding: utf-8 -*-
"""Submission_2_Recomendation System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-n4rssx3WCbSrT0Kbw4_l9_OsYb3GOag

# **Movie Recommendation System**

# **Business Understanding**
## **Problem Statements**
* Bagaimana cara meningkatakan user experience saat mencari film yang ingin ditonton ?
* Bagaimana cara membuat sistem rekomendasi film menggunakan metode collaborative filtering ?

## **Goals**
Meningkatakan user experience saat mencari film yang ingin ditonton.

## **Solution statements**
Dataset yang saya gunakan hanya berisi tentang rating atau hasil penilaian pengguna dan genre film, maka solusi yang sangat tepat untuk masalah ini adalah dengan menggunakan collaborative filtering.
[Collaborative Filtering](https://medium.com/@ranggaantok/bagaimana-sistem-rekomendasi-berkerja-e749dac64816): collaborative filtering adalah suatu konsep dimana opini dari pengguna lain yang ada digunakan untuk memprediksi item yang mungkin disukai/diminati oleh seorang pengguna.
Pada collaborative filtering attribut yang digunakan bukan konten tetapi user behaviour. contohnya kita merekomendasikan suatu item berdasarkan dari riwayat rating dari user tersebut maupun user lain.

![image](https://miro.medium.com/max/335/1*O6ON-kQ34pMCYOHSr7ZebQ.png)

# **Instalasi Kaggle**

Import kaggle untuk mengambil data
"""

!pip install -q kaggle

"""Masukkan file .json yang berisikan username dan key"""

from google.colab import files

files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

"""Megunduh dataset dari platform kaggle.com"""

!kaggle datasets download -d aigamer/movie-lens-dataset

"""# **Import Library**"""

import os
import zipfile
import numpy as np
import pandas as pd
import nltk
import keras
import tensorflow as tf
import seaborn as sns
from keras import layers
import matplotlib.pyplot as plt
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.feature_extraction.text import TfidfVectorizer
from collections import defaultdict
from keras.models import Model
from tensorflow.keras.optimizers import Adam
from keras.layers import Add, Activation, Lambda, BatchNormalization, Concatenate, Dropout, Input, Embedding, Dot, Reshape, Dense, Flatten
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau

"""# **Data Understanding**

Ekstraksi data
"""

local_zip = '/content/movie-lens-dataset.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

"""Membuat dataframe"""

movie_df = pd.read_csv('/content/movies.csv')
rating_df = pd.read_csv('/content/ratings.csv')
tags_df = pd.read_csv('/content/tags.csv')

"""Informasi Data"""

movie_df

movie_df.info()

movie_df.isnull().sum()

rating_df = rating_df.drop(['timestamp'],axis=1)
rating_df

rating_df.info()

rating_df.isnull().sum()

tags_df

tags_df.info()

tags_df.isnull().sum()

"""Menghapus missing value"""

movie_df = movie_df.dropna()
rating_df = rating_df.dropna()
tags_df = tags_df.dropna()

"""Informasi Data"""

rating_df.info()

"""Menggabungkan dataframe rating dan movie"""

new_movie_df = rating_df.merge(movie_df,how='inner',on='movieId')
new_movie_df.tail()

"""Normalisasi kolom rating"""

minRating = min(rating_df['rating'])
maxRating = max(rating_df['rating'])
rating_df['rating'] = rating_df["rating"].apply(lambda x: (x - minRating) / (maxRating - minRating)).values.astype(np.float32)
AvgRating = np.mean(rating_df['rating'])

"""Menampilkan rata-rata rating"""

print('Average Rating: ', AvgRating)

"""Memberikan id baru pada setiap baris di dataframe."""

# Membuat unique value dari userId
userIds = rating_df["userId"].unique().tolist()
# Membuat nilai sama dengan jumlah userID
encodedUser = {x: i for i, x in enumerate(userIds)}
encodeusertouser = {i: x for i, x in enumerate(userIds)}

# Membuat kolom user yang nilainya dihasilkan berdasarkan peroses generate nilai userId.
rating_df["user"] = rating_df["userId"].map(encodedUser)
nUsers = len(encodedUser)

# Membuat kolom user yang nilainya dihasilkan berdasarkan peroses generate nilai movieId.
movieIds = rating_df["movieId"].unique().tolist()
firstMovieEncoder = {x: i for i, x in enumerate(movieIds)}
movieEncoder = {i: x for i, x in enumerate(movieIds)}
rating_df["movie"] = rating_df["movieId"].map(firstMovieEncoder)
nMovie = len(firstMovieEncoder)

rating_df

print("Num of users: {}, Num of movie: {}".format(nUsers, nMovie))
print("Min rating: {}, Max rating: {}".format(min(rating_df['rating']), max(rating_df['rating'])))

"""Membagi jumlah data yang akan digunakan untuk proses training dan proses testing."""

# Mengacak sampel data
rating_df = rating_df.sample(frac=1, random_state=73)

X = rating_df[['user', 'movie']].values
Y = rating_df["rating"]

# Membagi data yang akan digunakan
test_size = 200000
train_indices = rating_df.shape[0] - test_size 
X_train, X_test, Y_train, Y_test = (X[:train_indices], X[train_indices:], Y[:train_indices], Y[train_indices:])

# Membagi X_train dan X_test untuk melatih model
X_train_array = [X_train[:, 0], X_train[:, 1]]
X_test_array = [X_test[:, 0], X_test[:, 1]]

"""Pembuatan arsitektur model dengan menggunakan embedding layer."""

def model_preparation():
    user = Input(name = 'user', shape = [1])
    user_embedding = Embedding(name = 'user_embedding', input_dim = nUsers, output_dim = 128)(user)

    movie = Input(name = 'movie', shape = [1])
    movie_embed = Embedding(name = 'movie_embedding', input_dim = nMovie, output_dim = 128)(movie)
    
    # Model mengguanakn layer Dot yang digunakan untuk komputasi antara embedding dari anime dan dari user.
    x = Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedding, movie_embed])
    x = Flatten()(x)
        
    x = Dense(1, kernel_initializer='he_normal')(x)
    x = BatchNormalization()(x)
    x = Activation("sigmoid")(x)
    
    model = Model(inputs=[user, movie], outputs=x)
    model.compile(
        loss='binary_crossentropy', 
        metrics=["mse", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],
        optimizer='Adam')
    
    return model

model = model_preparation()
model.summary()

"""Melakukan training model Embedding"""

# Menyimpan model terbaik dari proses training model.
best_model = ModelCheckpoint(
    filepath='./weights.h5', 
    save_weights_only=True, 
    monitor='val_loss', 
    mode='min', 
    save_best_only=True)

# Menghentikan proses training model apabila metrik mse tidak mengalami penurunan.
early_stopping = EarlyStopping(patience = 1, monitor='mse', mode='min', restore_best_weights=True)

my_callbacks = [
    best_model,
    early_stopping,   
]

"""Training model"""

hist = model.fit(
    x=X_train_array,
    y=Y_train,
    validation_data=(X_test_array, Y_test),
    epochs=30,
    batch_size=64,
    verbose=1,
    callbacks=my_callbacks,
)

model.load_weights('./weights.h5')

"""# **Membuat Plot**

Menampilkan plot loss
"""

# Membuat plot loss
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Loss Train', 'Loss Test'], loc='upper right')
plt.show()

"""Menampilkan plot mse"""

# Membuat plot mse
plt.plot(hist.history['mse'])
plt.plot(hist.history['val_mse'])
plt.ylabel('MSE')
plt.xlabel('Epoch')
plt.legend(['MSE Train', 'MSE Test'], loc='upper right')
plt.show()

"""Menampilkan plot recall"""

# Membuat plot recall
plt.plot(hist.history['recall'])
plt.plot(hist.history['val_recall'])
plt.ylabel('Recall')
plt.xlabel('Epoch')
plt.legend(['Recall Train', 'Recall Test'], loc='upper right')
plt.show()

"""Menampilkan plot precision"""

# Membuat plot precision
plt.plot(hist.history['precision'])
plt.plot(hist.history['val_precision'])
plt.ylabel('Precision')
plt.xlabel('Epoch')
plt.legend(['Precision Train', 'Precision Test'], loc='upper right')
plt.show()

"""# **Load model**

Melakukan load kembali weight model yang sebelumnya telah disimpan
"""

def load_weight(name, model):
    weights = model.get_layer(name).get_weights()[0]
    weights = weights / np.linalg.norm(weights, axis = 1).reshape((-1, 1))
    return weights

movie_weights = load_weight('movie_embedding', model)
user_weights = load_weight('user_embedding', model)

"""Mencari MovieId berdasarkan judul"""

def movie_data(movie):
    if isinstance(movie, int):
        return movie_df[movie_df.movieId == movie]
    if isinstance(anime, str):
        return movie_df[movie_df.title == movie]

"""# **Collaborative Filtering.**

Generate random user
"""

rating_by_user = rating_df.groupby('userId').size()
random_user = rating_by_user[rating_by_user < 1000].sample(1, random_state=None).index[0]
# Memasukkan id user secara random
print('User ID:', random_user)
top_movie_user = new_movie_df.groupby('userId').get_group(random_user)
top_movie_user[['rating', 'title', 'genres']].sort_values(
    by = 'rating',
    ascending=False
)

"""Mencari tingkat kemiripan user."""

def get_similar_users(tempId, n=10):
      index = tempId
      weights = user_weights
      dists = np.dot(weights, weights[encodedUser.get(index)])
      sortedDists = np.argsort(dists)
      n += 1
      closest = sortedDists[-n:]
      print('User that similar to user #{}'.format(tempId))
      
      SimilarArr = []
      
      for close in closest:
          similarity = dists[closest]

          if isinstance(tempId, int):
              SimilarArr.append({"similar_users": encodeusertouser.get(close), "similarity": similarity})

      Frame = pd.DataFrame(SimilarArr)
      return Frame

"""Emcari pengguna yang serupa."""

similar_users = get_similar_users(int(random_user), n=10)
similar_users = similar_users[similar_users.similar_users != random_user]
similar_users

"""Menampilkan list rekomendasi movie berdasarkan aktivitas tontonan movie pengguna."""

def get_user_movie_preference(userId, plot=False, temp=1):
  # Menentukan batas rating terendah movie
  lowest_rating = np.percentile(rating_df[rating_df.userId==userId].rating, 75)
  rating_df[rating_df.userId==userId] = rating_df[rating_df.userId==userId][rating_df[rating_df.userId==userId].rating >= lowest_rating]
  top_movie_refference = (
      rating_df[rating_df.userId==userId].sort_values(by="rating", ascending=False)
      .movieId.values
  )
  
  user_pref_df = movie_df[movie_df["movieId"].isin(top_movie_refference)]
  user_pref_df = user_pref_df[["movieId","title", "genres"]]
  
  if temp != 0:
      print("User #{} Already Rated {} movies with average rating = {:.1f}/5.0".format(
        userId, len(rating_df[rating_df.userId==userId]),
        rating_df[rating_df.userId==userId]['rating'].mean()*5,
      ))
      print('Recommended movie genre for user:')

  return user_pref_df

"""Menampilkan 10 rekomendasi movie untuk pengguna."""

reff_user = get_user_movie_preference(random_user, plot=True)
reff_user=pd.DataFrame(reff_user)
reff_user.head(10)